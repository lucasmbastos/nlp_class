{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import sklearn\n",
    "import nltk\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilitary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "def pre_processing(review):\n",
    "    review = review.lower()\n",
    "    review = cleanhtml(review)\n",
    "    return tokenizer.tokenize(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_dataset = pd.read_csv(\"../data/processed/acllib_data.csv\")\n",
    "usable_dataset = usable_dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVIEW</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[there, has, been, a, political, documentary, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[literally, every, aspect, of, this, science, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[gods, i, haven, t, watched, a, movie, this, a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[this, is, one, of, those, movies, that, appea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[being, a, bit, of, a, connoisseur, of, garbag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              REVIEW  SCORE\n",
       "0  [there, has, been, a, political, documentary, ...      1\n",
       "1  [literally, every, aspect, of, this, science, ...      0\n",
       "2  [gods, i, haven, t, watched, a, movie, this, a...      0\n",
       "3  [this, is, one, of, those, movies, that, appea...      0\n",
       "4  [being, a, bit, of, a, connoisseur, of, garbag...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.RegexpTokenizer(\"[a-z]+\")\n",
    "\n",
    "usable_dataset[\"REVIEW\"] = usable_dataset[\"REVIEW\"].map(pre_processing)\n",
    "usable_dataset[\"SCORE\"] = usable_dataset[\"SCORE\"].map(lambda x: 0 if x <5 else 1)\n",
    "usable_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean       234.139260\n",
       "std        173.495615\n",
       "min          6.000000\n",
       "25%        128.000000\n",
       "50%        176.000000\n",
       "75%        284.000000\n",
       "max       2487.000000\n",
       "Name: REVIEW, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_dataset[\"REVIEW\"].map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sentence_length = usable_dataset[\"REVIEW\"].map(len).describe()['75%'] + 1\n",
    "max_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_sentence(sentence):\n",
    "    tokens_to_fill = int(max_sentence_length - len(sentence))\n",
    "    \n",
    "    sentence.append('<END>')\n",
    "    sentence.extend(['<PAD>']*tokens_to_fill)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there',\n",
       " 'has',\n",
       " 'been',\n",
       " 'a',\n",
       " 'political',\n",
       " 'documentary',\n",
       " 'of',\n",
       " 'recent',\n",
       " 'vintage',\n",
       " 'called',\n",
       " 'why',\n",
       " 'we',\n",
       " 'fight',\n",
       " 'which',\n",
       " 'tries',\n",
       " 'to',\n",
       " 'examine',\n",
       " 'the',\n",
       " 'infamous',\n",
       " 'military',\n",
       " 'industrial',\n",
       " 'complex',\n",
       " 'and',\n",
       " 'its',\n",
       " 'grip',\n",
       " 'on',\n",
       " 'this',\n",
       " 'nation',\n",
       " 'it',\n",
       " 'is',\n",
       " 'considered',\n",
       " 'both',\n",
       " 'polemical',\n",
       " 'and',\n",
       " 'incisive',\n",
       " 'in',\n",
       " 'making',\n",
       " 'its',\n",
       " 'case',\n",
       " 'against',\n",
       " 'both',\n",
       " 'that',\n",
       " 'complex',\n",
       " 'and',\n",
       " 'the',\n",
       " 'war',\n",
       " 'fiasco',\n",
       " 'we',\n",
       " 'are',\n",
       " 'currently',\n",
       " 'involved',\n",
       " 'in',\n",
       " 'in',\n",
       " 'iraq',\n",
       " 'yet',\n",
       " 'a',\n",
       " 'far',\n",
       " 'more',\n",
       " 'famous',\n",
       " 'series',\n",
       " 'of',\n",
       " 'films',\n",
       " 'with',\n",
       " 'the',\n",
       " 'same',\n",
       " 'name',\n",
       " 'was',\n",
       " 'made',\n",
       " 'during',\n",
       " 'world',\n",
       " 'war',\n",
       " 'two',\n",
       " 'by',\n",
       " 'hollywood',\n",
       " 'director',\n",
       " 'frank',\n",
       " 'capra',\n",
       " 'although',\n",
       " 'considered',\n",
       " 'documentaries',\n",
       " 'and',\n",
       " 'having',\n",
       " 'won',\n",
       " 'oscars',\n",
       " 'in',\n",
       " 'that',\n",
       " 'category',\n",
       " 'this',\n",
       " 'series',\n",
       " 'of',\n",
       " 'seven',\n",
       " 'films',\n",
       " 'is',\n",
       " 'really',\n",
       " 'and',\n",
       " 'truly',\n",
       " 'mere',\n",
       " 'agitprop',\n",
       " 'more',\n",
       " 'in',\n",
       " 'the',\n",
       " 'vein',\n",
       " 'of',\n",
       " 'leni',\n",
       " 'reifenstal',\n",
       " 's',\n",
       " 'triumph',\n",
       " 'of',\n",
       " 'the',\n",
       " 'will',\n",
       " 'scenes',\n",
       " 'of',\n",
       " 'which',\n",
       " 'capra',\n",
       " 'recycles',\n",
       " 'for',\n",
       " 'his',\n",
       " 'own',\n",
       " 'purposes',\n",
       " 'that',\n",
       " 'said',\n",
       " 'that',\n",
       " 'fact',\n",
       " 'does',\n",
       " 'not',\n",
       " 'mean',\n",
       " 'it',\n",
       " 'does',\n",
       " 'not',\n",
       " 'have',\n",
       " 'vital',\n",
       " 'information',\n",
       " 'that',\n",
       " 'subsequent',\n",
       " 'generations',\n",
       " 'of',\n",
       " 'world',\n",
       " 'war',\n",
       " 'two',\n",
       " 'documentaries',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'bbc',\n",
       " 's',\n",
       " 'lauded',\n",
       " 'the',\n",
       " 'world',\n",
       " 'at',\n",
       " 'war',\n",
       " 'lacked',\n",
       " 'nor',\n",
       " 'does',\n",
       " 'that',\n",
       " 'mean',\n",
       " 'that',\n",
       " 'its',\n",
       " 'value',\n",
       " 'as',\n",
       " 'a',\n",
       " 'primary',\n",
       " 'source',\n",
       " 'is',\n",
       " 'any',\n",
       " 'the',\n",
       " 'less',\n",
       " 'valuable',\n",
       " 'they',\n",
       " 'are',\n",
       " 'skillfully',\n",
       " 'made',\n",
       " 'and',\n",
       " 'after',\n",
       " 'recently',\n",
       " 'purchasing',\n",
       " 'some',\n",
       " 'used',\n",
       " 'dvds',\n",
       " 'at',\n",
       " 'a',\n",
       " 'discount',\n",
       " 'store',\n",
       " 'i',\n",
       " 'found',\n",
       " 'myself',\n",
       " 'with',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'select',\n",
       " 'a',\n",
       " 'free',\n",
       " 'dvd',\n",
       " 'with',\n",
       " 'my',\n",
       " 'purchase',\n",
       " 'i',\n",
       " 'chose',\n",
       " 'goodtimes',\n",
       " 'dvd',\n",
       " 's',\n",
       " 'four',\n",
       " 'dvd',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'the',\n",
       " 'series',\n",
       " 'rarely',\n",
       " 'has',\n",
       " 'something',\n",
       " 'free',\n",
       " 'been',\n",
       " 'so',\n",
       " 'worth',\n",
       " 'invaluable',\n",
       " 'while',\n",
       " 'there',\n",
       " 'are',\n",
       " 'no',\n",
       " 'extras',\n",
       " 'on',\n",
       " 'the',\n",
       " 'dvds',\n",
       " 'and',\n",
       " 'the',\n",
       " 'sound',\n",
       " 'quality',\n",
       " 'of',\n",
       " 'the',\n",
       " 'prints',\n",
       " 'varies',\n",
       " 'these',\n",
       " 'films',\n",
       " 'provide',\n",
       " 'insight',\n",
       " 'into',\n",
       " 'the',\n",
       " 'minds',\n",
       " 'of',\n",
       " 'americans',\n",
       " 'two',\n",
       " 'thirds',\n",
       " 'of',\n",
       " 'a',\n",
       " 'century',\n",
       " 'ago',\n",
       " 'when',\n",
       " 'racism',\n",
       " 'was',\n",
       " 'overt',\n",
       " 'as',\n",
       " 'in',\n",
       " 'many',\n",
       " 'of',\n",
       " 'the',\n",
       " 'classic',\n",
       " 'warner',\n",
       " 'brothers',\n",
       " 'pro',\n",
       " 'war',\n",
       " 'cartoons',\n",
       " 'of',\n",
       " 'the',\n",
       " 'era',\n",
       " 'and',\n",
       " 'there',\n",
       " 'was',\n",
       " 'nothing',\n",
       " 'wrong',\n",
       " 'with',\n",
       " 'blatant',\n",
       " 'distortion',\n",
       " 'of',\n",
       " 'facts',\n",
       " 'the',\n",
       " 'seven',\n",
       " 'films',\n",
       " 'produced',\n",
       " 'between',\n",
       " 'and',\n",
       " 'are',\n",
       " 'prelude',\n",
       " 'to',\n",
       " 'war',\n",
       " 'the',\n",
       " 'nazis',\n",
       " 'strike',\n",
       " 'divide',\n",
       " 'and',\n",
       " 'conquer',\n",
       " 'the',\n",
       " 'battle',\n",
       " 'of',\n",
       " 'britain',\n",
       " 'the',\n",
       " 'battle',\n",
       " 'of',\n",
       " 'russia',\n",
       " 'the',\n",
       " 'battle',\n",
       " 'of',\n",
       " 'china',\n",
       " 'and',\n",
       " 'war',\n",
       " 'comes',\n",
       " 'to',\n",
       " 'america',\n",
       " 'overall',\n",
       " 'the',\n",
       " 'film',\n",
       " 'series',\n",
       " 'is',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'watching',\n",
       " 'not',\n",
       " 'only',\n",
       " 'for',\n",
       " 'the',\n",
       " 'obvious',\n",
       " 'reasons',\n",
       " 'but',\n",
       " 'for',\n",
       " 'the',\n",
       " 'subtle',\n",
       " 'things',\n",
       " 'it',\n",
       " 'reveals',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'the',\n",
       " 'plural',\n",
       " 'for',\n",
       " 'terms',\n",
       " 'like',\n",
       " 'x',\n",
       " 'millions',\n",
       " 'when',\n",
       " 'referring',\n",
       " 'to',\n",
       " 'dollars',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'the',\n",
       " 'modern',\n",
       " 'singular',\n",
       " 'or',\n",
       " 'the',\n",
       " 'most',\n",
       " 'overused',\n",
       " 'graphic',\n",
       " 'in',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'series',\n",
       " 'a',\n",
       " 'japanese',\n",
       " 'sword',\n",
       " 'piercing',\n",
       " 'the',\n",
       " 'center',\n",
       " 'of',\n",
       " 'manchuria',\n",
       " 'yet',\n",
       " 'it',\n",
       " 'also',\n",
       " 'shows',\n",
       " 'the',\n",
       " 'complexities',\n",
       " 'of',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'apply',\n",
       " 'past',\n",
       " 'standards',\n",
       " 'to',\n",
       " 'current',\n",
       " 'wars',\n",
       " 'the',\n",
       " 'lesson',\n",
       " 'of',\n",
       " 'world',\n",
       " 'war',\n",
       " 'one',\n",
       " 'avoid',\n",
       " 'foreign',\n",
       " 'entanglements',\n",
       " 'was',\n",
       " 'not',\n",
       " 'applicable',\n",
       " 'to',\n",
       " 'world',\n",
       " 'war',\n",
       " 'two',\n",
       " 'whose',\n",
       " 'own',\n",
       " 'lesson',\n",
       " 'act',\n",
       " 'early',\n",
       " 'against',\n",
       " 'dictatorships',\n",
       " 'has',\n",
       " 'not',\n",
       " 'been',\n",
       " 'applicable',\n",
       " 'in',\n",
       " 'the',\n",
       " 'three',\n",
       " 'major',\n",
       " 'wars',\n",
       " 'america',\n",
       " 'has',\n",
       " 'fought',\n",
       " 'since',\n",
       " 'korea',\n",
       " 'vietnam',\n",
       " 'nor',\n",
       " 'iraq',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'much',\n",
       " 'of',\n",
       " 'this',\n",
       " 'series',\n",
       " 'teeters',\n",
       " 'on',\n",
       " 'the',\n",
       " 'uncertainties',\n",
       " 'of',\n",
       " 'the',\n",
       " 'times',\n",
       " 'it',\n",
       " 'was',\n",
       " 'made',\n",
       " 'in',\n",
       " 'only',\n",
       " 'underscores',\n",
       " 'its',\n",
       " 'historic',\n",
       " 'value',\n",
       " 'in',\n",
       " 'today',\n",
       " 's',\n",
       " 'information',\n",
       " 'clogged',\n",
       " 'times',\n",
       " 'it',\n",
       " 'may',\n",
       " 'not',\n",
       " 'help',\n",
       " 'you',\n",
       " 'sort',\n",
       " 'out',\n",
       " 'the',\n",
       " 'truth',\n",
       " 'from',\n",
       " 'the',\n",
       " 'lies',\n",
       " 'and',\n",
       " 'propaganda',\n",
       " 'of',\n",
       " 'today',\n",
       " 'but',\n",
       " 'at',\n",
       " 'least',\n",
       " 'you',\n",
       " 'll',\n",
       " 'realize',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'the',\n",
       " 'first',\n",
       " 'to',\n",
       " 'be',\n",
       " 'in',\n",
       " 'such',\n",
       " 'a',\n",
       " 'tenuous',\n",
       " 'position',\n",
       " 'nor',\n",
       " 'will',\n",
       " 'you',\n",
       " 'be',\n",
       " 'the',\n",
       " 'last',\n",
       " '<END>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_dataset[\"REVIEW\"] = usable_dataset[\"REVIEW\"].map(fill_sentence)\n",
    "usable_dataset.loc[0,\"REVIEW\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, validate_set, test_set = np.split(usable_dataset.sample(frac=1), [int(.6*len(usable_dataset)), int(.8*len(usable_dataset))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"../data/processed/glove.6b.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miranda/Documents/academico/mestrado/monitoria/workshop/venv/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('brazilian', 0.7331621050834656),\n",
       " ('argentina', 0.672882080078125),\n",
       " ('portugal', 0.647482693195343),\n",
       " ('paraguay', 0.601586639881134),\n",
       " ('paulo', 0.59923255443573),\n",
       " ('uruguay', 0.5989081263542175),\n",
       " ('venezuela', 0.5980018973350525),\n",
       " ('peru', 0.5975527167320251),\n",
       " ('ecuador', 0.5785552859306335),\n",
       " ('bolivia', 0.5705569386482239)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.similar_by_vector(\"brazil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add utility vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.add(['<PAD>','<END>'], [[0.1]*300,[0.2]*300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miranda/Documents/academico/mestrado/monitoria/workshop/venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'of'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.index2word[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f35d536ae80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding LSTM Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miranda/Documents/academico/mestrado/monitoria/workshop/venv/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model.add(\n",
    "    keras.layers.Embedding(\n",
    "        input_dim=len(word2vec_model.wv.vocab),\n",
    "        output_dim=300,\n",
    "        input_length=max_sentence_length\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(keras.layers.LSTM(300, return_sequences=True))\n",
    "model.add(keras.layers.LSTM(300, return_sequences=True))\n",
    "model.add(keras.layers.Dense(150, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
